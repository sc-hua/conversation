#!/usr/bin/env python3
"""
å¤šæ¨¡æ€å¯¹è¯å¯¼å‡ºå·¥å…·

å°†å¯¹è¯è®°å½•è½¬æ¢ä¸º LLaMA-Factory å…¼å®¹çš„å¤šæ¨¡æ€æ ¼å¼ï¼Œ
æ”¯æŒå›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šç§æ¨¡æ€å†…å®¹ã€‚
"""
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
from ..core.modules import History, Message, Content, ContentBlock


class MultimodalExporter:
    """å¤šæ¨¡æ€å¯¹è¯è®°å½•å¯¼å‡ºå™¨"""
    
    def __init__(self, conversations_dir: str = None):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        Args:
            conversations_dir: å¯¹è¯è®°å½•ç›®å½•
        """
        if conversations_dir is None:
            conversations_dir = os.getenv("HISTORY_SAVE_DIR", "./log/conv_log/draft")
        self.conversations_dir = Path(conversations_dir)
        
    def load_conversation(self, conversation_file: str) -> Optional[History]:
        """åŠ è½½å¯¹è¯è®°å½•æ–‡ä»¶"""
        try:
            file_path = self.conversations_dir / conversation_file
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # é‡æ„æ¶ˆæ¯æ ¼å¼
            messages = []
            for msg_data in data.get('messages', []):
                if isinstance(msg_data['content'], dict) and 'blocks' in msg_data['content']:
                    # ç»“æ„åŒ–å†…å®¹
                    content = Content()
                    for block in msg_data['content']['blocks']:
                        content.blocks.append(ContentBlock(
                            type=block['type'],
                            content=block['content'],
                            extras=block.get('extras', {})
                        ))
                else:
                    # ç®€å•æ–‡æœ¬å†…å®¹
                    content = msg_data['content']
                
                messages.append(Message(
                    msg_id=msg_data['msg_id'],
                    role=msg_data['role'],
                    content=content,
                    timestamp=datetime.fromisoformat(msg_data['timestamp'])
                ))
            
            return History(
                conv_id=data['conv_id'],
                messages=messages,
                created_at=datetime.fromisoformat(data['created_at']),
                updated_at=datetime.fromisoformat(data['updated_at']),
                system_prompt=data.get('system_prompt'),
                metadata=data.get('metadata')
            )
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¯¹è¯æ–‡ä»¶å¤±è´¥ {conversation_file}: {e}")
            return None
    
    def extract_media_content(self, content_block: ContentBlock) -> Dict[str, Any]:
        """æå–åª’ä½“å†…å®¹ä¿¡æ¯"""
        media_info = {
            'placeholder': '',
            'file_path': None,
            'media_type': None
        }
        
        if content_block.type == 'image':
            media_info['placeholder'] = '<image>'
            # ä¼˜å…ˆä½¿ç”¨ resolved_pathï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹ content
            resolved_path = content_block.get_extra('resolved_path')
            media_info['file_path'] = resolved_path if resolved_path else content_block.content
            media_info['media_type'] = 'image'
        elif content_block.type == 'audio':
            media_info['placeholder'] = '<audio>'
            media_info['file_path'] = content_block.content
            media_info['media_type'] = 'audio'
        elif content_block.type == 'video':
            media_info['placeholder'] = '<video>'
            media_info['file_path'] = content_block.content
            media_info['media_type'] = 'video'
            
        return media_info
    
    def convert_to_llamafactory_format(self, conversation: History) -> Dict[str, Any]:
        """è½¬æ¢ä¸º LLaMA-Factory æ ¼å¼"""
        result = {
            'messages': [],
            'images': [],
            'audios': [],
            'videos': []
        }
        
        # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯ï¼Œåªå¤„ç†ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯
        user_assistant_messages = [msg for msg in conversation.messages 
                                 if msg.role in ['user', 'assistant']]
        
        current_message_content = ""
        current_media_files = {'images': [], 'audios': [], 'videos': []}
        
        for i, message in enumerate(user_assistant_messages):
            if isinstance(message.content, Content):
                # å¤„ç†ç»“æ„åŒ–å†…å®¹
                content_parts = []
                
                for block in message.content.blocks:
                    if block.type == 'text':
                        content_parts.append(block.content)
                    elif block.type in ['image', 'audio', 'video']:
                        media_info = self.extract_media_content(block)
                        content_parts.append(media_info['placeholder'])
                        
                        # æ”¶é›†åª’ä½“æ–‡ä»¶ï¼Œä½¿ç”¨å®é™…çš„æ–‡ä»¶è·¯å¾„
                        file_path = media_info['file_path']
                        if block.type == 'image':
                            current_media_files['images'].append(file_path)
                        elif block.type == 'audio':
                            current_media_files['audios'].append(file_path)
                        elif block.type == 'video':
                            current_media_files['videos'].append(file_path)
                    elif block.type == 'json':
                        # JSONæ•°æ®è½¬ä¸ºæ–‡æœ¬æè¿°
                        json_text = f"æ•°æ®: {json.dumps(block.content, ensure_ascii=False)}"
                        content_parts.append(json_text)
                
                current_message_content = "".join(content_parts)
            else:
                # ç®€å•æ–‡æœ¬å†…å®¹
                current_message_content = str(message.content)
            
            # æ·»åŠ æ¶ˆæ¯
            result['messages'].append({
                'role': message.role,
                'content': current_message_content
            })
            
            # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ï¼Œè¡¨ç¤ºä¸€è½®å¯¹è¯ç»“æŸï¼Œä¿å­˜åª’ä½“æ–‡ä»¶
            if message.role == 'assistant':
                if current_media_files['images']:
                    result['images'].extend(current_media_files['images'])
                if current_media_files['audios']:
                    result['audios'].extend(current_media_files['audios'])
                if current_media_files['videos']:
                    result['videos'].extend(current_media_files['videos'])
                
                # é‡ç½®åª’ä½“æ–‡ä»¶æ”¶é›†å™¨
                current_media_files = {'images': [], 'audios': [], 'videos': []}
        
        # æ¸…ç†ç©ºçš„åª’ä½“æ•°ç»„
        if not result['images']:
            del result['images']
        if not result['audios']:
            del result['audios']
        if not result['videos']:
            del result['videos']
            
        return result
    
    def export_conversation(self, conversation_file: str, output_file: str = None, output_dir: str = None) -> bool:
        """å¯¼å‡ºå•ä¸ªå¯¹è¯ä¸º LLaMA-Factory æ ¼å¼
        
        Args:
            conversation_file: å¯¹è¯æ–‡ä»¶å
            output_file: è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœæœªæŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆ
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨å¯¹è¯ç›®å½•
        """
        conversation = self.load_conversation(conversation_file)
        if not conversation:
            return False
        
        llamafactory_data = self.convert_to_llamafactory_format(conversation)
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir:
            output_directory = Path(output_dir)
            output_directory.mkdir(parents=True, exist_ok=True)
        else:
            output_directory = self.conversations_dir
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if not output_file:
            base_name = Path(conversation_file).stem
            output_file = f"{base_name}_llamafactory.json"
        
        try:
            output_path = output_directory / output_file
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump([llamafactory_data], f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å¯¼å‡ºæˆåŠŸ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    def export_all_conversations(self, output_file: str = "exported_conversations.json", output_dir: str = None) -> bool:
        """å¯¼å‡ºæ‰€æœ‰å¯¹è¯ä¸ºå•ä¸ª LLaMA-Factory æ ¼å¼æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶å
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨å¯¹è¯ç›®å½•
        """
        all_conversations = []
        
        # éå†æ‰€æœ‰å¯¹è¯æ–‡ä»¶
        for file_path in self.conversations_dir.glob("*.json"):
            if file_path.name.endswith("_llamafactory.json"):
                continue  # è·³è¿‡å·²å¯¼å‡ºçš„æ–‡ä»¶
                
            conversation = self.load_conversation(file_path.name)
            if conversation:
                llamafactory_data = self.convert_to_llamafactory_format(conversation)
                all_conversations.append(llamafactory_data)
                print(f"ğŸ“„ å¤„ç†: {file_path.name}")
        
        if not all_conversations:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¯¼å‡ºçš„å¯¹è¯è®°å½•")
            return False
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir:
            output_directory = Path(output_dir)
            output_directory.mkdir(parents=True, exist_ok=True)
        else:
            output_directory = self.conversations_dir
        
        try:
            output_path = output_directory / output_file
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(all_conversations, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ‰¹é‡å¯¼å‡ºæˆåŠŸ: {output_path}")
            print(f"ğŸ“Š å¯¼å‡ºå¯¹è¯æ•°é‡: {len(all_conversations)}")
            return True
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    def list_conversations(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¯¹è¯æ–‡ä»¶"""
        conversations = []
        for file_path in self.conversations_dir.glob("*.json"):
            if not file_path.name.endswith("_llamafactory.json"):
                conversations.append(file_path.name)
        return sorted(conversations)
    
    def preview_conversation(self, conversation_file: str) -> None:
        """é¢„è§ˆå¯¹è¯è½¬æ¢ç»“æœ"""
        conversation = self.load_conversation(conversation_file)
        if not conversation:
            return
        
        print(f"ğŸ“„ å¯¹è¯é¢„è§ˆ: {conversation_file}")
        print(f"ğŸ†” å¯¹è¯ID: {conversation.conv_id}")
        print(f"ğŸ“… åˆ›å»ºæ—¶é—´: {conversation.created_at}")
        print(f"ğŸ’¬ æ¶ˆæ¯æ•°é‡: {len(conversation.messages)}")
        print()
        
        # æ˜¾ç¤ºæ¶ˆæ¯æ¦‚è§ˆ
        for i, message in enumerate(conversation.messages, 1):
            content_preview = ""
            if isinstance(message.content, Content):
                parts = []
                for block in message.content.blocks:
                    if block.type == 'text':
                        text = str(block.content)[:50]
                        if len(str(block.content)) > 50:
                            text += "..."
                        parts.append(text)
                    elif block.type == 'image':
                        parts.append(f"[å›¾ç‰‡: {block.content}]")
                    elif block.type == 'json':
                        parts.append(f"[JSONæ•°æ®]")
                content_preview = " ".join(parts)
            else:
                content_preview = str(message.content)[:100]
                if len(str(message.content)) > 100:
                    content_preview += "..."
            
            print(f"{i}. {message.role}: {content_preview}")
        
        print()
        
        # æ˜¾ç¤ºè½¬æ¢åçš„æ ¼å¼
        llamafactory_data = self.convert_to_llamafactory_format(conversation)
        print("ğŸ”„ LLaMA-Factory æ ¼å¼é¢„è§ˆ:")
        print(f"  æ¶ˆæ¯æ•°é‡: {len(llamafactory_data['messages'])}")
        if 'images' in llamafactory_data:
            print(f"  å›¾ç‰‡æ–‡ä»¶: {len(llamafactory_data['images'])} ä¸ª")
            for img in llamafactory_data['images']:
                print(f"    - {img}")
        if 'audios' in llamafactory_data:
            print(f"  éŸ³é¢‘æ–‡ä»¶: {len(llamafactory_data['audios'])} ä¸ª")
        if 'videos' in llamafactory_data:
            print(f"  è§†é¢‘æ–‡ä»¶: {len(llamafactory_data['videos'])} ä¸ª")
        print()


def main():
    """å‘½ä»¤è¡Œå·¥å…·ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ğŸ“š å¤šæ¨¡æ€å¯¹è¯å¯¼å‡ºå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python export_tools.py list
  python export_tools.py preview conv.json
  python export_tools.py export conv.json --output_file output.json --output_dir ./exports
  python export_tools.py export-all --output_file all_convs.json --output_dir ./exports
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # list å‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰å¯¹è¯æ–‡ä»¶')
    
    # preview å‘½ä»¤
    preview_parser = subparsers.add_parser('preview', help='é¢„è§ˆå¯¹è¯è½¬æ¢ç»“æœ')
    preview_parser.add_argument('file', help='å¯¹è¯æ–‡ä»¶å')
    
    # export å‘½ä»¤
    export_parser = subparsers.add_parser('export', help='å¯¼å‡ºå•ä¸ªå¯¹è¯')
    export_parser.add_argument('file', help='å¯¹è¯æ–‡ä»¶å')
    export_parser.add_argument('--output_file', help='è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    export_parser.add_argument('--output_dir', help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºå¯¹è¯ç›®å½•ï¼‰')
    
    # export-all å‘½ä»¤
    export_all_parser = subparsers.add_parser('export-all', help='å¯¼å‡ºæ‰€æœ‰å¯¹è¯')
    export_all_parser.add_argument('--output_file', default='exported_conversations.json', help='è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤: exported_conversations.jsonï¼‰')
    export_all_parser.add_argument('--output_dir', help='è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºå¯¹è¯ç›®å½•ï¼‰')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        print()
        
        # æ˜¾ç¤ºå¯ç”¨å¯¹è¯
        exporter = MultimodalExporter()
        conversations = exporter.list_conversations()
        if conversations:
            print(f"ğŸ“„ å¯ç”¨å¯¹è¯æ–‡ä»¶ ({len(conversations)} ä¸ª):")
            for i, conv in enumerate(conversations[:5], 1):
                print(f"  {i}. {conv}")
            if len(conversations) > 5:
                print(f"  ... å’Œå…¶ä»– {len(conversations) - 5} ä¸ªæ–‡ä»¶")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯¹è¯æ–‡ä»¶")
        return
    
    exporter = MultimodalExporter()
    
    if args.command == "list":
        conversations = exporter.list_conversations()
        print(f"ğŸ“„ å¯¹è¯æ–‡ä»¶åˆ—è¡¨ ({len(conversations)} ä¸ª):")
        for conv in conversations:
            print(f"  - {conv}")
            
    elif args.command == "preview":
        exporter.preview_conversation(args.file)
        
    elif args.command == "export":
        exporter.export_conversation(args.file, args.output_file, args.output_dir)
        
    elif args.command == "export-all":
        exporter.export_all_conversations(args.output_file, args.output_dir)


if __name__ == "__main__":
    main()
