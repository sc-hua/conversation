"""
å¢å¼ºçš„LangGraphå¯¹è¯ç³»ç»Ÿï¼Œæ”¯æŒç»“æ„åŒ–å†…å®¹å®šä½ã€‚

æœ¬æ¨¡å—ä½¿ç”¨LangGraphå®ç°æ ¸å¿ƒå¯¹è¯å›¾ï¼Œ
é«˜çº§æ”¯æŒç»“æ„åŒ–å†…å®¹å’Œä½ç½®æ„ŸçŸ¥å¤„ç†ã€‚
"""

import asyncio
from typing import Dict, Optional, Any
from models import ConversationState, Message, StructuredMessageContent
from conversation_manager import ConversationManager
from llm import create_llm
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class ConversationGraph:
    """
    LangGraphå¯¹è¯ç³»ç»Ÿï¼Œæ”¯æŒç»“æ„åŒ–å†…å®¹å’Œå¹¶å‘æ§åˆ¶ã€‚
    
    å‚æ•°:
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        llm_type: LLMç±»å‹ï¼ˆ'mock'ã€'ollama'ã€'openai'ï¼‰
    å±æ€§:
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹
        conversation_manager: å¯¹è¯ç®¡ç†å™¨
        semaphore: å¹¶å‘ä¿¡å·é‡
    """

    def __init__(self, max_concurrent: int = 5, llm_type: str = None):
        self.llm = create_llm(llm_type)
        self.conversation_manager = ConversationManager()
        self.semaphore = asyncio.Semaphore(max_concurrent)

    async def _process_input(self, state: ConversationState) -> ConversationState:
        """
        åŠ è½½å†å²ï¼Œå¿…è¦æ—¶æ·»åŠ ç³»ç»Ÿæç¤ºã€‚
        å‚æ•° / è¿”å›: state: ConversationState
        """
        existing_messages = self.conversation_manager.get_conversation_history(
            state.conversation_id
        )
        state.messages = existing_messages
        
        # å¦‚æœæ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œåˆ™æ·»åŠ ç³»ç»Ÿæç¤º
        if not state.messages and state.system_prompt:
            system_msg = Message(role="system", content=state.system_prompt)
            state.messages.append(system_msg)
            self.conversation_manager.save_message(state.conversation_id, system_msg)
        return state

    async def _generate_response(self, state: ConversationState) -> ConversationState:
        """
        ç”¨LLMç”ŸæˆAIå›å¤ã€‚
        å‚æ•° / è¿”å›: state: ConversationState
        """
        if state.current_input:
            response = await self.llm.generate_response(state.messages, state.current_input)
            state.response = response
        return state

    async def _save_history(self, state: ConversationState) -> ConversationState:
        """
        ä¿å­˜ç”¨æˆ·è¾“å…¥å’ŒAIå›å¤åˆ°å†å²ã€‚
        å‚æ•° / è¿”å›: state: ConversationState
        """
        if state.current_input:
            user_msg = Message(role="user", content=state.current_input)
            self.conversation_manager.save_message(state.conversation_id, user_msg)
        if state.response:
            assistant_msg = Message(role="assistant", content=state.response)
            self.conversation_manager.save_message(state.conversation_id, assistant_msg)
        
        # é‡æ–°åŠ è½½å®Œæ•´å¯¹è¯å†å²ä»¥æ›´æ–° state.messages
        state.messages = self.conversation_manager.get_conversation_history(
            state.conversation_id
        )
        return state

    async def chat(self,
                   conversation_id: Optional[str] = None,
                   system_prompt: Optional[str] = None,
                   structured_content: Optional[StructuredMessageContent] = None,
                   is_final: bool = False) -> Dict[str, Any]:
        """
        ä¸»èŠå¤©æ¥å£ï¼Œæ”¯æŒç»“æ„åŒ–å†…å®¹ã€‚
        å‚æ•°:
            conversation_id: å¯¹è¯ID
            system_prompt: ç³»ç»Ÿæç¤º
            structured_content: ç»“æ„åŒ–è¾“å…¥
            is_final: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
        è¿”å›: dict
        """
        async with self.semaphore:  # æ§åˆ¶å¹¶å‘
            state = ConversationState(
                conversation_id=conversation_id or ConversationState().conversation_id,
                system_prompt=system_prompt,
                current_input=structured_content
            )
            
            # æ‰§è¡Œå¯¹è¯å›¾ï¼šå¤„ç† â†’ ç”Ÿæˆ â†’ ä¿å­˜
            state = await self._process_input(state)
            state = await self._generate_response(state)
            state = await self._save_history(state)
            
            # å¦‚æœæ ‡è®°ä¸ºæœ€ç»ˆï¼Œåˆ™ä¿å­˜å®Œæ•´å¯¹è¯
            if is_final:
                file_path = await self.conversation_manager.save_conversation_to_file(
                    state.conversation_id
                )
                self.conversation_manager.cleanup_memory(state.conversation_id)
                print(f"ğŸ’¾ Conversation ä¿å­˜åˆ°: {file_path}")
            return {
                "conversation_id": state.conversation_id,
                "response": state.response,
                "message_count": len(state.messages),
                "input_preview": (state.current_input.to_display_text() 
                                if state.current_input else None)
            }
