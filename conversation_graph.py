"""
å¢å¼ºçš„LangGraphå¯¹è¯ç³»ç»Ÿï¼Œæ”¯æŒç»“æ„åŒ–å†…å®¹å®šä½ã€‚

æœ¬æ¨¡å—ä½¿ç”¨LangGraphå®ç°æ ¸å¿ƒå¯¹è¯å›¾ï¼Œ
é«˜çº§æ”¯æŒç»“æ„åŒ–å†…å®¹å’Œä½ç½®æ„ŸçŸ¥å¤„ç†ã€‚
"""

import asyncio
from typing import Dict, Optional, Any
from models import ConversationState, Message, StructuredMessageContent
from conversation_manager import ConversationManager
from llm import create_llm
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class ConversationGraph:
    """
    LangGraph å®ç°ï¼Œæ”¯æŒå¯é…ç½®çš„ LLMã€‚

    å®ç°ä¸‰èŠ‚ç‚¹å¯¹è¯å·¥ä½œæµï¼šè¾“å…¥å¤„ç†ã€å“åº”ç”Ÿæˆå’Œå†å²ä¿å­˜ï¼Œå®Œæ•´æ”¯æŒå¸¦ä½ç½®ä¿¡æ¯çš„å¤šæ¨¡æ€å†…å®¹ã€‚

    å±æ€§:
        llm: å¯é…ç½®çš„è¯­è¨€æ¨¡å‹å®ä¾‹
        conversation_manager: ç®¡ç†å¯¹è¯æŒä¹…åŒ–
        semaphore: æ§åˆ¶å¹¶å‘å¤„ç†
    """
    
    def __init__(self, max_concurrent: int = 5, llm_type: str = None):
        """
        åˆå§‹åŒ–å¯¹è¯å›¾å¹¶é…ç½®å¯é€‰çš„ LLMã€‚

        å‚æ•°:
            max_concurrent: æœ€å¤§å¹¶å‘å¯¹è¯æ•°
            llm_type: è¦ä½¿ç”¨çš„ LLM ç±»å‹ï¼ˆ'mock'ã€'ollama'ã€'openai'ï¼‰
        """
        self.llm = create_llm(llm_type)
        self.conversation_manager = ConversationManager()
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def _process_input(self, state: ConversationState) -> ConversationState:
        """
        Process user input and load conversation history.
        
        First node in the conversation graph that handles input processing
        and loads existing conversation history if available.
        
        å‚æ•°:
            state: å½“å‰å¯¹è¯çŠ¶æ€
            
        è¿”å›:
            åŠ è½½å†å²åçš„æ›´æ–°å¯¹è¯çŠ¶æ€
        """
    # åŠ è½½ç°æœ‰å¯¹è¯å†å²
        existing_messages = self.conversation_manager.get_conversation_history(
            state.conversation_id
        )
        state.messages = existing_messages
        
    # å¦‚æœæ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œåˆ™æ·»åŠ ç³»ç»Ÿæç¤º
        if not state.messages and state.system_prompt:
            system_msg = Message(role="system", content=state.system_prompt)
            state.messages.append(system_msg)
            self.conversation_manager.save_message(state.conversation_id, system_msg)
        
        return state
    
    async def _generate_response(self, state: ConversationState) -> ConversationState:
        """
        ä½¿ç”¨è¯­è¨€æ¨¡å‹ç”ŸæˆAIå“åº”ã€‚
        
        å¯¹è¯å›¾ä¸­çš„ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼Œå¤„ç†ç»“æ„åŒ–
        è¾“å…¥å¹¶ç”Ÿæˆé€‚å½“çš„å“åº”ã€‚
        
        å‚æ•°:
            state: å½“å‰å¯¹è¯çŠ¶æ€
            
        è¿”å›:
            ç”Ÿæˆå“åº”åçš„æ›´æ–°å¯¹è¯çŠ¶æ€
        """
        if state.current_input:
            response = await self.llm.generate_response(state.messages, state.current_input)
            state.response = response
        return state
    
    async def _save_history(self, state: ConversationState) -> ConversationState:
        """
        å°†å¯¹è¯æ¶ˆæ¯ä¿å­˜åˆ°å†å²è®°å½•ã€‚
        
        å¯¹è¯å›¾ä¸­çš„ç¬¬ä¸‰ä¸ªèŠ‚ç‚¹ï¼Œå°†ç”¨æˆ·
        è¾“å…¥å’ŒAIå“åº”æŒä¹…åŒ–åˆ°å¯¹è¯å†å²ã€‚
        
        å‚æ•°:
            state: å½“å‰å¯¹è¯çŠ¶æ€
            
        è¿”å›:
            ä¿å­˜æ¶ˆæ¯åçš„æ›´æ–°å¯¹è¯çŠ¶æ€
        """
        # ä¿å­˜å¸¦ç»“æ„åŒ–å†…å®¹çš„ç”¨æˆ·æ¶ˆæ¯
        if state.current_input:
            user_msg = Message(role="user", content=state.current_input)
            # ä»…ä¿å­˜åˆ° conversation managerï¼Œè€Œä¸æ·»åŠ åˆ° state.messages
            # ä»¥é¿å…åœ¨ä¸‹æ¬¡åŠ è½½å¯¹è¯æ—¶é‡å¤
            self.conversation_manager.save_message(state.conversation_id, user_msg)
        
        # ä¿å­˜åŠ©æ‰‹å“åº”
        if state.response:
            assistant_msg = Message(role="assistant", content=state.response)
            # ä»…ä¿å­˜åˆ° conversation manager
            self.conversation_manager.save_message(state.conversation_id, assistant_msg)
        
    # é‡æ–°åŠ è½½å®Œæ•´å¯¹è¯å†å²ä»¥æ›´æ–° state.messages
        state.messages = self.conversation_manager.get_conversation_history(
            state.conversation_id
        )
        
        return state
    
    async def chat(self,
                   conversation_id: Optional[str] = None,
                   system_prompt: Optional[str] = None,
                   structured_content: Optional[StructuredMessageContent] = None,
                   is_final: bool = False) -> Dict[str, Any]:
        """
        å¸¦ç»“æ„åŒ–å†…å®¹æ”¯æŒçš„ä¸»èŠå¤©æ¥å£ã€‚
        
        å¤„ç†å¯¹è¯è½®æ¬¡ï¼Œæ”¯æŒå¤æ‚çš„å¤šæ¨¡æ€
        å†…å®¹å®šä½å¹¶ç»´æŠ¤å¯¹è¯å†å²ã€‚
        
        å‚æ•°:
            conversation_id: ç°æœ‰å¯¹è¯IDæˆ–Noneè¡¨ç¤ºæ–°å¯¹è¯
            system_prompt: AIè¡Œä¸ºçš„ç³»ç»Ÿæç¤ºè¯ï¼ˆä»…é¦–æ¡æ¶ˆæ¯ï¼‰
            structured_content: å¸¦ä½ç½®å†…å®¹å—çš„ç»“æ„åŒ–è¾“å…¥
            is_final: æ˜¯å¦å°†å®Œæ•´å¯¹è¯ä¿å­˜åˆ°æ–‡ä»¶
            
        è¿”å›:
            åŒ…å«conversation_idã€responseã€message_countå’Œinput_previewçš„å­—å…¸
        """
        async with self.semaphore:  # æ§åˆ¶å¹¶å‘
            # Create conversation state
            state = ConversationState(
                conversation_id=conversation_id or ConversationState().conversation_id,
                system_prompt=system_prompt,
                current_input=structured_content
            )
            
            # æ‰§è¡Œå¯¹è¯å›¾ï¼šå¤„ç† â†’ ç”Ÿæˆ â†’ ä¿å­˜
            state = await self._process_input(state)
            state = await self._generate_response(state)
            state = await self._save_history(state)
            
            # å¦‚æœæ ‡è®°ä¸ºæœ€ç»ˆï¼Œåˆ™ä¿å­˜å®Œæ•´å¯¹è¯
            if is_final:
                file_path = await self.conversation_manager.save_conversation_to_file(
                    state.conversation_id
                )
                self.conversation_manager.cleanup_memory(state.conversation_id)
                print(f"ğŸ’¾ Conversation ä¿å­˜åˆ°: {file_path}")
            
            return {
                "conversation_id": state.conversation_id,
                "response": state.response,
                "message_count": len(state.messages),
                "input_preview": (state.current_input.to_display_text() 
                                if state.current_input else None)
            }
