#!/usr/bin/env python3
"""ç®€æ´çš„æ—¥å¿—ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹"""

import asyncio
import os
from conversation.utils.logging import get_logger, log_exception

# è·å–æ—¥å¿—å™¨
logger = get_logger()
chat_logger = get_logger("chat")
file_logger = get_logger("file")


def basic_example():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== åŸºç¡€æ—¥å¿—ç¤ºä¾‹ ===")
    logger.debug("Debug message")
    logger.info("Program started")
    logger.warning("This is a warning")
    logger.error("This is an error")


@log_exception
def normal_function():
    """å¸¦å¼‚å¸¸å¤„ç†çš„æ™®é€šå‡½æ•°"""
    logger.info("Executing normal function")
    return "Success"


@log_exception  
async def async_function():
    """å¸¦å¼‚å¸¸å¤„ç†çš„å¼‚æ­¥å‡½æ•°"""
    logger.info("Executing async function")
    await asyncio.sleep(0.1)
    return "Async success"


def module_example():
    """å¤šæ¨¡å—æ—¥å¿—ç¤ºä¾‹"""
    print("\n=== æ¨¡å—æ—¥å¿—ç¤ºä¾‹ ===")
    chat_logger.info("Chat module: Processing user message")
    file_logger.info("File module: Saving conversation")


async def conversation_example():
    """å¯¹è¯ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== å¯¹è¯ç³»ç»Ÿç¤ºä¾‹ ===")
    
    conv_id = "test_123"
    logger.info(f"[Conversation started] | conv_id={conv_id}")

    # æ¨¡æ‹ŸLLMè°ƒç”¨
    llm_logger = get_logger("llm")
    llm_logger.info("[LLM API call] | Starting OpenAI API")

    await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚

    llm_logger.info("[LLM API call] | API call successful | tokens=150")
    logger.info(f"[Conversation ended] | conv_id={conv_id}")


async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ æ—¥å¿—ç³»ç»Ÿç¤ºä¾‹")
    
    basic_example()
    normal_function()
    await async_function()
    module_example() 
    await conversation_example()
    
    print("\nâœ… ç¤ºä¾‹å®Œæˆï¼ŒæŸ¥çœ‹ ./log/conversation.log")


if __name__ == "__main__":
    # è®¾ç½®DEBUGçº§åˆ«æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
    os.environ["LOG_LEVEL"] = "DEBUG"
    asyncio.run(main())
