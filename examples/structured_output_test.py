#!/usr/bin/env python3
"""
æµ‹è¯•ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½çš„ç®€å•ç¤ºä¾‹
"""

import asyncio
import os
from typing import List, Literal
from pydantic import BaseModel, Field

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

from conversation.core import Content, ConversationGraph


# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class Event(BaseModel):
    event: str = Field(..., description="äº‹ä»¶ä»£ç ï¼Œéœ€è¦ä¸ºè‹±æ–‡ï¼Œå¯ä»¥æœ‰ä¸‹åˆ’çº¿")
    level: Literal["critical", "caution", "suggestion"] = Field(..., description="äº‹ä»¶ç±»å‹")
    analyze: str = Field(..., max_length=50, description="50å­—ä»¥å†…ä¸­æ–‡åˆ†æäº‹ä»¶")
    message: str = Field(..., max_length=15, description="15å­—ä»¥å†…ä¸­æ–‡æè¿°, æç¤º")
    confidence: float = Field(..., ge=0.0, le=1.0, description="ç½®ä¿¡åº¦ï¼Œ0.0-1.0")


class Notice(BaseModel):
    notice: str = Field(..., max_length=15, description="15å­—ä»¥å†…ä¸­æ–‡æè¿°, æç¤º")
    priority: float = Field(..., ge=0.0, le=1.0, description="æ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜")


class Caption(BaseModel):
    events: List[Event] = Field(..., description="äº‹ä»¶åˆ—è¡¨")
    notices: List[Notice] = Field(..., description="é€šçŸ¥åˆ—è¡¨")


async def test_structured_output():
    """æµ‹è¯•ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½"""
    
    # æ£€æŸ¥OpenAIé…ç½®
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½...")
    
    # åˆ›å»ºå¯¹è¯å›¾å®ä¾‹
    graph = ConversationGraph(llm='openai')
    
    # åˆ›å»ºè¾“å…¥å†…å®¹
    content = Content("éšæ„ç”Ÿæˆä¸€äº›äº‹ä»¶å’Œé€šçŸ¥ï¼Œè¦æ±‚äº‹ä»¶æœ‰3ä¸ªï¼Œé€šçŸ¥æœ‰2ä¸ªã€‚")
    
    try:
        # æµ‹è¯•æ™®é€šè¾“å‡ºï¼ˆä¸ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼ï¼‰
        print("\nğŸ“ æµ‹è¯•1: æ™®é€šæ–‡æœ¬è¾“å‡º")
        result1 = await graph.chat(
            content=content,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚"
        )
        print(f"æ™®é€šè¾“å‡º: {result1['response']}")
        
        # æµ‹è¯•ç»“æ„åŒ–è¾“å‡º
        print("\nğŸ”§ æµ‹è¯•2: ç»“æ„åŒ–JSONè¾“å‡º")
        result2 = await graph.chat(
            content=content,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚",
            response_format=Caption  # ä½¿ç”¨Pydanticæ¨¡å‹é™åˆ¶è¾“å‡ºæ ¼å¼
        )
        print(f"ç»“æ„åŒ–è¾“å‡º: {result2['response']}")
        
        # éªŒè¯JSONæ ¼å¼
        import json
        try:
            parsed = json.loads(result2['response'])
            print("âœ… JSONæ ¼å¼éªŒè¯é€šè¿‡")
            
            # éªŒè¯Pydanticæ¨¡å‹
            caption = Caption(**parsed)
            print(f"âœ… Pydanticæ¨¡å‹éªŒè¯é€šè¿‡")
            print(f"   - äº‹ä»¶æ•°é‡: {len(caption.events)}")
            print(f"   - é€šçŸ¥æ•°é‡: {len(caption.notices)}")
            
        except Exception as e:
            print(f"âŒ æ ¼å¼éªŒè¯å¤±è´¥: {e}")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        
    finally:
        # æ¸…ç†
        if 'result1' in locals():
            await graph.end(result1['conv_id'], save=False)
        if 'result2' in locals():
            await graph.end(result2['conv_id'], save=False)


async def test_mock_structured_output():
    """ä½¿ç”¨Mock LLMæµ‹è¯•ç»“æ„åŒ–è¾“å‡ºæ¥å£å…¼å®¹æ€§"""
    print("\nğŸ§ª æµ‹è¯•Mock LLMçš„ç»“æ„åŒ–è¾“å‡ºæ¥å£å…¼å®¹æ€§...")
    
    graph = ConversationGraph(llm='mock')
    content = Content("æµ‹è¯•Mock LLM")
    
    try:
        result = await graph.chat(
            content=content,
            response_format=Caption  # Mock LLMåº”è¯¥å¿½ç•¥è¿™ä¸ªå‚æ•°
        )
        print(f"âœ… Mock LLMå…¼å®¹æ€§æµ‹è¯•é€šè¿‡: {result['response']}")
        await graph.end(result['conv_id'], save=False)
        
    except Exception as e:
        print(f"âŒ Mock LLMæµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    async def run_tests():
        await test_structured_output()
        await test_mock_structured_output()
    
    try:
        asyncio.run(run_tests())
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
