{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdf16c0",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a424c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话的开头问题\")\n",
    "    punchline: str = Field(description=\"笑点答案\")\n",
    "    tags: List[str] = Field(description=\"笑话的标签列表\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb341b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48481d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa41f5",
   "metadata": {},
   "source": [
    "# code / langchain Pydantic output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms.openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 定义 Pydantic 模型\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话的开头问题\")\n",
    "    punchline: str = Field(description=\"笑点答案\")\n",
    "    tags: List[str] = Field(description=\"笑话的标签列表\")\n",
    "\n",
    "# 2. 创建解析器\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# 3. 获取格式指令\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# 4. 构建提示模板\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户查询。\\n{format_instructions}\\n\\n查询: {query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# 5. 调用 LLM 并解析\n",
    "llm = OpenAI(\n",
    "    model_name=os.getenv(\"OPENAI_MODEL\"),\n",
    ")\n",
    "\n",
    "query = \"讲一个关于程序员的笑话\"\n",
    "_input = prompt.format_prompt(query=query)\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "# 解析输出\n",
    "parsed_output = parser.parse(output)\n",
    "\n",
    "# 打印结果\n",
    "print(\"原始输出:\\n\", output)\n",
    "print(\"\\n解析后的对象:\\n\", parsed_output)\n",
    "print(\"\\n访问字段:\\n\", parsed_output.setup)  # 直接访问字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fe04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd86d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6999871f",
   "metadata": {},
   "source": [
    "# code / sglang struct output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febd403e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-bfb4e009c73b49329f0fe98ee592c71f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Paris\",\\n  \"population\": 2148000\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None, token_ids=None)], created=1756979245, model='ovis2.5-9b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=22, total_tokens=45, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, prompt_token_ids=None, kv_transfer_params=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyexpat import model\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# SGLang 方式：使用 Pydantic 模型\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str = Field(..., pattern=r\"^\\w+$\", description=\"Name of the capital city\")\n",
    "    population: int = Field(..., description=\"Population of the capital city\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"OPENAI_MODEL\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please generate the information of the capital of France in the JSON format.\"}],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"foo\",\n",
    "            \"schema\": CapitalInfo.model_json_schema(),\n",
    "        },\n",
    "    },\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3565eca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Paris\",\\n  \"population\": 2148000\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d99332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3311890a",
   "metadata": {},
   "source": [
    "# code / langchain PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 定义 Pydantic 模型（与 SGLang 相同）\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str = Field(..., pattern=r\"^\\w+$\", description=\"Name of the capital city\")\n",
    "    population: int = Field(..., description=\"Population of the capital city\")\n",
    "\n",
    "# 创建解析器\n",
    "parser = PydanticOutputParser(pydantic_object=CapitalInfo)\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 创建模型\n",
    "model = ChatOpenAI(\n",
    "    model_name=os.getenv(\"OPENAI_MODEL\"),\n",
    ")\n",
    "\n",
    "# 创建链\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 调用\n",
    "result = chain.invoke({\"query\": \"Please generate the information of the capital of France in the JSON format.\"})\n",
    "print(result)  # 输出: CapitalInfo(name='Paris', population=2147000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f944a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f221a014",
   "metadata": {},
   "source": [
    "# code / langchain / with_structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cb64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw': AIMessage(content='{\\n  \"name\": \"Paris\",\\n  \"population\": 2148000\\n}', additional_kwargs={'parsed': CapitalInfo(name='Paris', population=2148000), 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 22, 'total_tokens': 45, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'ovis2.5-9b', 'system_fingerprint': None, 'id': 'chatcmpl-1d8a474744f449b9a7d2f0b191f48d21', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--127294e5-8f49-4b42-af73-debc97cedeef-0', usage_metadata={'input_tokens': 22, 'output_tokens': 23, 'total_tokens': 45, 'input_token_details': {}, 'output_token_details': {}}), 'parsed': CapitalInfo(name='Paris', population=2148000), 'parsing_error': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 定义 Pydantic 模型\n",
    "class CapitalInfo(BaseModel):\n",
    "    name: str = Field(..., pattern=r\"^\\w+$\", description=\"Name of the capital city\")\n",
    "    population: int = Field(..., description=\"Population of the capital city\")\n",
    "\n",
    "# 创建模型并绑定结构化输出\n",
    "model = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL\"))\n",
    "structured_model = model.with_structured_output(CapitalInfo, include_raw=True)\n",
    "\n",
    "# 直接调用\n",
    "result = structured_model.invoke(\"Please generate the information of the capital of France in the JSON format.\")\n",
    "print(result)  # 输出: CapitalInfo(name='Paris', population=2147000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6de2f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw', 'parsed', 'parsing_error'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b90f103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CapitalInfo(name='Paris', population=2148000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9670bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CapitalInfo"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df522d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04918271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e53c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f345fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON格式输出:\n",
      "{\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"event\": \"机器突然停止工作\",\n",
      "      \"type\": \"critical\",\n",
      "      \"analyze\": \"机器停机可能影响生产进度和安全，需立即排查原因。\",\n",
      "      \"message\": \"机器故障，立即检查。\",\n",
      "      \"confidence\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"event\": \"工人尝试重启机器失败\",\n",
      "      \"type\": \"caution\",\n",
      "      \"analyze\": \"重启失败表明问题复杂，可能涉及硬件或软件故障，需专业人员介入。\",\n",
      "      \"message\": \"重启失败，联系技术人员。\",\n",
      "      \"confidence\": 0.8\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "YAML格式输出:\n",
      "events:\n",
      "- event: 机器突然停止工作\n",
      "  type: critical\n",
      "  analyze: 机器停机可能导致生产中断和安全隐患\n",
      "  message: 机器停机，需紧急处理\n",
      "  confidence: 0.9\n",
      "- event: 工人尝试重启机器失败\n",
      "  type: caution\n",
      "  analyze: 重启失败可能预示更严重故障，需进一步检查\n",
      "  message: 重启失败，需排查原因\n",
      "  confidence: 0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Literal, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "# 1. 定义数据模型\n",
    "class EventItem(BaseModel):\n",
    "    event: str = Field(..., description=\"事件描述\")\n",
    "    type: Literal[\"critical\", \"caution\", \"suggestion\"] = Field(..., description=\"事件类型\")\n",
    "    analyze: str = Field(..., max_length=50, description=\"50字以内分析事件\")\n",
    "    message: str = Field(..., max_length=15, description=\"15字以内中文描述，提示\")\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0, description=\"置信度，0.0-1.0\")\n",
    "\n",
    "class EventsList(BaseModel):\n",
    "    events: List[EventItem] = Field(..., description=\"事件列表\")\n",
    "\n",
    "# 2. 创建系统提示生成函数\n",
    "def create_scene_system_prompt_xxx_out(output_format: str):\n",
    "    format_dict = {\n",
    "        \"JSON\": \"\"\"\n",
    "# Format / 输出格式 (严格遵守，不得新增或修改顶级字段)\n",
    "[\n",
    "   {\n",
    "      \"event\": \"<string>\", \n",
    "      \"type\": \"<critical|caution|suggestion>\", \n",
    "      \"analyze\": \"<string, 50字以内分析事件>\", \n",
    "      \"message\": \"<string, 15字以内中文描述, 提示>\", \n",
    "      \"confidence\": <float, 0.0-1.0>\n",
    "   },\n",
    "   # ... more events\n",
    "]\n",
    "\"\"\",\n",
    "        \"YAML\": \"\"\"\n",
    "# Format / 输出格式 (严格遵守，不得新增或修改顶级字段)\n",
    "events:\n",
    "  - event: <string>\n",
    "    type: <critical|caution|suggestion>\n",
    "    analyze: <string, 50字以内分析事件>\n",
    "    message: <string, 15字以内中文描述, 提示>\n",
    "    confidence: <float, 0.0-1.0>\n",
    "  # ... more events\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "你是一个场景分析专家，需要根据输入的场景描述生成结构化的事件列表。\n",
    "\n",
    "请严格按照以下{output_format}格式输出：\n",
    "\n",
    "{format_dict[output_format]}\n",
    "\n",
    "要求：\n",
    "1. 严格遵守输出格式，不得新增或修改顶级字段\n",
    "2. 每个事件必须包含所有必需字段\n",
    "3. analyze字段必须在50字以内\n",
    "4. message字段必须在15字以内\n",
    "5. confidence必须是0.0-1.0之间的浮点数\n",
    "6. type只能是critical、caution或suggestion之一\n",
    "\"\"\"\n",
    "    return system_prompt\n",
    "\n",
    "# 3. 创建事件生成器类\n",
    "class EventGenerator:\n",
    "    def __init__(self, model_name=\"gpt-4o\", temperature=0):\n",
    "        self.model = ChatOpenAI(model=model_name, temperature=temperature)\n",
    "        # 预先创建结构化模型\n",
    "        self.structured_model = self.model.with_structured_output(EventsList)\n",
    "    \n",
    "    def generate_events(self, scene_description: str, output_format: str = \"JSON\") -> dict:\n",
    "        \"\"\"生成结构化事件列表\"\"\"\n",
    "        if output_format == \"JSON\":\n",
    "            return self._generate_json_events(scene_description)\n",
    "        elif output_format == \"YAML\":\n",
    "            return self._generate_yaml_events(scene_description)\n",
    "        else:\n",
    "            raise ValueError(\"不支持的输出格式，请选择'JSON'或'YAML'\")\n",
    "    \n",
    "    def _generate_json_events(self, scene_description: str) -> dict:\n",
    "        \"\"\"生成JSON格式事件列表\"\"\"\n",
    "        system_prompt = create_scene_system_prompt_xxx_out(\"JSON\")\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=f\"场景描述：{scene_description}\")\n",
    "        ]\n",
    "        \n",
    "        # 使用 with_structured_output 直接返回 Pydantic 对象\n",
    "        result = self.structured_model.invoke(messages)\n",
    "        return result.model_dump()\n",
    "    \n",
    "    def _generate_yaml_events(self, scene_description: str) -> dict:\n",
    "        \"\"\"生成YAML格式事件列表\"\"\"\n",
    "        system_prompt = create_scene_system_prompt_xxx_out(\"YAML\")\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"场景描述：{scene}\")\n",
    "        ])\n",
    "        \n",
    "        # 使用 with_structured_output\n",
    "        chain = prompt | self.structured_model\n",
    "        result = chain.invoke({\"scene\": scene_description})\n",
    "        \n",
    "        # 返回字典格式，由调用者决定是否转换为 YAML 字符串\n",
    "        return result.model_dump()\n",
    "\n",
    "# 4. 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    generator = EventGenerator(\n",
    "        model_name=os.getenv(\"OPENAI_MODEL\"),\n",
    "    )\n",
    "    scene = \"一个工厂中，机器突然停止工作，工人试图重启但失败。\"\n",
    "    \n",
    "    # 生成JSON格式\n",
    "    json_result = generator.generate_events(scene, \"JSON\")\n",
    "    print(\"JSON格式输出:\")\n",
    "    print(json.dumps(json_result, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # 生成YAML格式\n",
    "    yaml_result = generator.generate_events(scene, \"YAML\")\n",
    "    print(\"\\nYAML格式输出:\")\n",
    "    print(yaml.dump(yaml_result, allow_unicode=True, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd30e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
